from bokeh.io import show
from bokeh.models import Label
from bokeh.plotting import figure
from joblib import dump, load as jload
from os import path
from numpy import mean, ndarray, flip, zeros, argsort, vstack, array
from scipy.sparse import csr_matrix
from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.manifold import TSNE
from sklearn.pipeline import Pipeline

from Config import config


# Directory path
dir_path: str = path.dirname(path.realpath(__file__))


def load(file_name: str) -> Pipeline:
    return jload(path.join(dir_path, f"{file_name}.sav"))


def save(model: Pipeline, file_name: str) -> None:
    dump(model, path.join(dir_path, f"{file_name}.sav"))


def get_keys(topic_matrix: ndarray) -> ndarray:
    """
    returns an integer list of predicted topic
    categories for a given topic matrix
    """
    return topic_matrix.argmax(axis=1).tolist()


def extract_top_words(
        n: int,
        keys: ndarray,
        document_term_matrix: csr_matrix | ndarray,
        pipeline: Pipeline | TfidfVectorizer
) -> list[str]:
    """

    Args:
        n: Number of words to extract.
        keys: Keys array generated by the get_keys function.
        document_term_matrix: Term matrix generated by the model.
        pipeline: Pipeline of the model or its vectorizer.

    Returns:
        A list of n_topic strings, where each string contains the n most common
        words in a predicted category, in order

    """
    s: ndarray | csr_matrix | int

    top_word_indices: list[list[int]] = [
        flip(
            argsort(
                s.toarray()
            )[0][-n:],
            0
        ) for topic in range(config.training.n_topics) if type(
            s := sum(
                (document_term_matrix[i] for i, k in enumerate(keys) if k == topic),
                0
            )
        ) is not int
    ]

    vect: TfidfVectorizer = pipeline.named_steps['vect'] if type(pipeline) is Pipeline else pipeline

    def mapper(index: int) -> str:
        """

        Args:
            index: Index of the word

        Returns:
            The extracted word from the vectorizer.

        """
        temp_word_vector: ndarray = zeros(
            (1, document_term_matrix.shape[1])
        )
        temp_word_vector[:, index] = 1

        return vect.inverse_transform(temp_word_vector)[0][0].encode('ascii').decode('utf-8')

    return [
        " ".join(
            map(
                mapper,
                topic
            )
        ) for topic in top_word_indices
    ]


def get_mean_topic_vectors(
        keys: ndarray, 
        two_dim_vectors: ndarray
) -> list[list[float]]:
    """

    Args:
        keys: Array of keys generated by the get_keys function.
        two_dim_vectors: Matrix to apply the keys on.

    Returns:
        The mean topic of the given matrix of vectors.

    """
    return list(
        map(
            lambda t: mean(
                vstack([two_dim_vectors[i] for i, k in enumerate(keys) if k == t]),
                axis=0
            ),
            range(config.training.n_topics)
        )
    )


def apply_tsne(
        n_topics: int,
        model: LatentDirichletAllocation | TruncatedSVD, 
        vect: TfidfVectorizer, 
        term_mat: ndarray
) -> None:
    """
    
    Args:
        n_topics: Number of unique topics.
        model: Model to test.
        vect: Vectorizer of the model.
        term_mat: Term matrix from the model.

    """
    topic_matrix: ndarray = model.fit_transform(term_mat)
    keys: ndarray = get_keys(topic_matrix)

    tsne_model: TSNE = TSNE(
        n_components=2,
        perplexity=50,
        learning_rate=100,
        n_iter=2000,
        verbose=1,
        random_state=0,
        angle=0.75
    )
    tsne_lda_vectors: ndarray = tsne_model.fit_transform(topic_matrix)

    # Colormap for the plot
    colormap = array([
        "#1f77b4", "#aec7e8", "#ff7f0e", "#ffbb78", "#2ca02c",
        "#98df8a", "#d62728", "#ff9896", "#9467bd", "#c5b0d5",
        "#8c564b", "#c49c94", "#e377c2", "#f7b6d2", "#7f7f7f",
        "#c7c7c7", "#bcbd22", "#dbdb8d", "#17becf", "#9edae5"])[:n_topics]

    top_words: list[str] = extract_top_words(3, keys, term_mat, vect)

    mean_topic_vectors = get_mean_topic_vectors(keys, tsne_lda_vectors)

    plot = figure(title="t-SNE Clustering of {} LDA Topics".format(n_topics))
    plot.scatter(x=tsne_lda_vectors[:, 0], y=tsne_lda_vectors[:, 1], color=colormap[keys])

    for t in range(n_topics):
        label = Label(x=mean_topic_vectors[t][0], y=mean_topic_vectors[t][1],
                      text=top_words[t], text_color=colormap[t])
        plot.add_layout(label)

    show(plot)


def extract_topic(model: Pipeline, n: int, title: str) -> list[str]:
    """

    Args:
        model: Model to use.
        n:  Top n-words to return.
        title: String from which to extract the topic.

    Returns:
        List of most popular words for the topic in decreasing order of popularity.

    """
    sample: ndarray = array([title.lower()])
    vect: TfidfVectorizer = model.named_steps['vect']

    return extract_top_words(
        n,
        get_keys(model.transform(sample)),
        vect.transform(sample),
        vect
    )
